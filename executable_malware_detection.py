from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import  LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import mean_squared_error, classification_report
from xgboost import XGBClassifier
import pandas as pd
import time


def apply_decision_tree(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
    decision_model = DecisionTreeClassifier(random_state=1)
    decision_model.fit(x_train, y_train)

    predict = decision_model.predict(x_test)
    print(classification_report(y_test, predict))
    print(f'decision tree result is: {mean_squared_error(y_test, predict)}')


def apply_random_forest(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
    forest_model = RandomForestClassifier(random_state=1)
    forest_model.fit(x_train, y_train)

    predict = forest_model.predict(x_test)
    predict = [round(item) for item in predict]
    print(classification_report(y_test, predict))
    print(f'random forest result is: {mean_squared_error(y_test, predict)}')


def apply_XGBoost(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
    xgb_model = XGBClassifier(use_label_encoder=False)
    xgb_model.fit(x_train, y_train)

    predict = xgb_model.predict(x_test)
    print(classification_report(y_test, predict))
    print(f'XGBoost result is: {mean_squared_error(y_test, predict)}')


def apply_logistic_regression(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
    logistic_model = LogisticRegression(random_state=0)
    logistic_model.fit(x_train, y_train)

    predict = logistic_model.predict(x_test)
    print(classification_report(y_test, predict))
    print(f'logistic regression result is: {mean_squared_error(y_test, predict)}')


def apply_svm_classification(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
    svm_model = SVC(random_state=0)
    svm_model.fit(x_train, y_train)

    predict = svm_model.predict(x_test)
    print(classification_report(y_test, predict))
    print(f'SVM classification result is: {mean_squared_error(y_test, predict)}')


def apply_naive_bayes(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
    naive_bayes_model = GaussianNB()
    naive_bayes_model.fit(x_train, y_train)

    predict = naive_bayes_model.predict(x_test)
    print(classification_report(y_test, predict))
    print(f'naive bayes classification result is: {mean_squared_error(y_test, predict)}')


def malware_detect():
    start = time.time()
    dataset = pd.read_csv("ClaMP_Raw-5184.csv")
    dataset = dataset[dataset < 2**31].fillna(0)

    features = dataset.columns[:-1]
    x = dataset.loc[:, features]
    y = dataset["class"]

    apply_decision_tree(x, y)
    apply_XGBoost(x, y)
    apply_random_forest(x, y)

    end = time.time()
    print(f'time passed is: {end - start}')


if __name__ == '__main__':
    malware_detect()
